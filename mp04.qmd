---
title: "Mini-Project #04: Just the Fact(-Check)s, Ma’am!"
format:
  html:
    toc: true
    toc-location: left
    smooth-scroll: true
    theme: pulse
    code-fold: true       # <-- code folding here
execute:
  echo: true
  warning: false
  message: false
---

# Introdution

Beginning in 2024, the trustworthiness of the Bureau of Labor Statistics came under scrutiny. Claims from multiple politicians have been circulating that the recent US employment numbers, and the subsequent revisions, could not be trusted. Particularly, some statements asserted that the jobs numbers had been purposefully overstated and then later revised downwards.

These claims received greater attention following President Donald Trump's public criticism of the BLS. Then, in 2025, Trump removed Biden-nominated BLS Commissioner Erika McEntarfer, citing "rigged" jobs reports and downward revisions to employment numbers as evidence that the agency's data was inaccurate, manipulated, and politically biased.

**Did the BLS really rig the jobs reports through overstatement of employment numbers and downward revisions?**

Revisions to monthly employment estimates are a routine part of the Bureau of Labor Statistics data process. Initial numbers are based on incomplete surveys given to households and businesses and are later revised as more payroll information becomes available. This data collection process results in both upward and downward revisions, regardless of the political climate.

The key question we will address in our analysis is whether the recent revisions significantly and meaningfully depart from historical patterns and trends. If the revisions in recent years are unusually large, frequent or disproportionately negative compared to previous decades, this would lend support to the claims that the BLS's employment data is unreliable. If not, revisions may just reflect the normal uncertainty with typical data collection processes in real-time measurement.

# Data Aquistion


To begin our analysis we download the CES Estimates and the CES Revisions data sets directly from the Bureau of Labr Statistics. 

## Downloading Final CES Estimates 


```{r}

library(httr2)
library(rvest)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(knitr)

#  Send POST request using httr2
resp <- httr2::request("https://data.bls.gov/pdq/SurveyOutputServlet") |>
  httr2::req_method("POST") |>
  httr2::req_headers(
    "Content-Type" = "application/x-www-form-urlencoded",
    "Origin"       = "https://data.bls.gov",
    "Referer"      = "https://data.bls.gov/pdq/SurveyOutputServlet",
    "User-Agent"   = "Mozilla/5.0"
  ) |>
  httr2::req_body_form(
    request_action     = "get_data",
    reformat           = "true",
    from_results_page  = "true",
    from_year          = "1979",
    to_year            = "2025",
    initial_request    = "false",
    data_tool          = "surveymost",
    series_id          = "CES0000000001",
    years_option       = "specific_years"
  ) |>
  httr2::req_perform()

# Parse HTML and grab the correct (second) table
html <- httr2::resp_body_html(resp)

tables <- html |>
  rvest::html_elements("table")

# first table is metadata, second is Year/Jan...Dec
ces_raw <- tables[[2]] |>
  rvest::html_table()

#  Reshape Year/Jan...Dec into monthly date + level
ces_levels <- ces_raw |>
  tidyr::pivot_longer(
    cols      = -Year,          # all columns except Year
    names_to  = "month",
    values_to = "level"
  ) |>
  dplyr::mutate(
    ym_str = paste(Year, month),          # "1979 Jan"
    date   = lubridate::ym(ym_str),       # 1979-01-01
    level  = as.numeric(gsub(",", "", level))
  ) |>
  dplyr::select(date, level) |>
  dplyr::arrange(date) |>
  dplyr::filter(
    date >= as.Date("1979-01-01"),
    date <= as.Date("2025-07-01")
  ) |>
  tidyr::drop_na()

kable(
  ces_levels,
  format  = "html",
  caption = "Nonfarm Payroll Levels"
)

```

## Downloading CES Revisions
 



```{r}

library(httr2)
library(rvest)
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(tibble)
library(knitr)

# Avoid HTTP/2 issues 
options(curl_http_version = 2)

# reques with hhtr2 
url_ces <- "https://www.bls.gov/web/empsit/cesnaicsrev.htm"

req_ces <- httr2::request(url_ces) |>
  httr2::req_method("GET") |>
  httr2::req_headers(
    "User-Agent"      = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0",
    "Accept"          = "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language" = "en-US,en;q=0.5",
    "Referer"         = "https://www.bls.gov/",
    "Connection"      = "keep-alive"
  ) |>
  httr2::req_options(http_version = 2L)  # HTTP/1.1

resp_ces <- httr2::req_perform(req_ces)

page_ces <- resp_ces |>
  httr2::resp_body_html()


# Returns: date, original, final, revision
get_ces_revisions_year <- function(year, html_page = page_ces) {

  heading_pattern <- sprintf(
    "Nonfarm Payroll Employment: Revisions between over-the-month estimates, %d",
    year
  )

  # All tables after the heading
  table_nodes <- html_page |>
    rvest::html_elements(
      xpath = sprintf("//*[contains(., '%s')][1]/following::table", heading_pattern)
    )

  if (length(table_nodes) == 0) {
    stop("No tables found for year ", year)
  }

  # Pick the first table with at least 12 rows
  tbl_raw <- NULL
  for (node in table_nodes) {
    tmp <- suppressWarnings(rvest::html_table(node, header = FALSE, fill = TRUE))
    if (nrow(tmp) >= 12) {
      tbl_raw <- tibble::as_tibble(tmp)
      break
    }
  }

  if (is.null(tbl_raw)) {
    stop("No suitable (>= 12 rows) table found for year ", year)
  }

  # Clean: first 12 rows = Jan–Dec
  tbl_clean <- tbl_raw |>
    dplyr::slice(1:12) |>
    dplyr::select(
      month    = 1,   # not used for date, but this is month name
      original = 3,   # first estimate
      final    = 5    # third estimate
    ) |>
    dplyr::mutate(
      #  month index
      month_index = dplyr::row_number(),

      # Build date as "YYYY-MM-01" using the year argument
      date = as.Date(sprintf("%d-%02d-01", year, month_index)),

      # Clean numeric text: keep only digits and minus sign
      original_str = stringr::str_replace_all(original, "[^0-9-]", ""),
      final_str    = stringr::str_replace_all(final,    "[^0-9-]", ""),

      # Convert to numeric with warnings suppressed
      original = suppressWarnings(as.numeric(original_str)),
      final    = suppressWarnings(as.numeric(final_str)),

      revision = final - original
    ) |>
    dplyr::select(date, original, final, revision)

  tbl_clean
}

# apply to all years
years_vec <- 1979:2025

ces_revisions_all <- purrr::map_dfr(
  years_vec,
  get_ces_revisions_year
)

#  Filter to jan 1979 – jun 2025 
ces_revisions <- ces_revisions_all |>
  dplyr::filter(
    date >= as.Date("1979-01-01"),
    date <= as.Date("2025-06-01")
  ) |>
  dplyr::arrange(date)



```

## Task 3 Join Tables

```{r}


library(dplyr)
library(lubridate)

ces_full <- ces_levels |>
  inner_join(ces_revisions, by = "date") |>
  arrange(date) |>
  mutate(
    year      = year(date),
    decade    = floor(year / 10) * 10,
    month_num = month(date),
    month_lab = factor(
      month(date, label = TRUE, abbr = TRUE),
      levels = month.abb
    ),
    abs_revision     = abs(revision),
    pct_revision     = if_else(final != 0, revision / final, NA_real_),
    abs_pct_revision = abs(pct_revision)
  )


```

## Largest Revisions

### When was the largest positive Revision?

```{r}
library(dplyr)
library(knitr)

# Largest positive revision (Final - Original > 0)
largest_positive <- ces_full |>
  filter(revision > 0, !is.na(revision)) |>
  arrange(desc(revision)) |>
  slice(1)


# formatted HTML table
largest_positive_table <- largest_positive |>
  transmute(
    Date                         = date,
     `Payroll level (jobs)` =
      formatC(level * 1000, format = "f", digits = 0, big.mark = ","),

    `Original employment (jobs)` =
      formatC(original * 1000, format = "f", digits = 0, big.mark = ","),

    `Final employment (jobs)` =
      formatC(final * 1000, format = "f", digits = 0, big.mark = ","),

    `Revision (jobs)` =
      formatC(revision * 1000, format = "f", digits = 0, big.mark = ","),

    `Revision (%)` =
      paste0(round(pct_revision * 100, 2), "%")
  ) |>
  as.data.frame()

kable(
  largest_positive_table,
  caption  = "Largest Positive CES Payroll Revision (Final − Original)",
  format   = "html",
  big.mark = ","
)

```

The largest **positive** revision was in **December of 1984**. 


### When was the largest negative revision?

```{r}
library(dplyr)
library(knitr)

# Largest NEGATIVE revision (most negative Final - Original)
largest_negative <- ces_full |>
  filter(!is.na(revision)) |>
  arrange(revision) |>        # most negative first
  slice(1)

# Format for HTML table
largest_negative_table <- largest_negative |>
  transmute(
    Date = date,

    `Payroll level (jobs)` =
      formatC(level * 1000, format = "f", digits = 0, big.mark = ","),

    `Original employment (jobs)` =
      formatC(original * 1000, format = "f", digits = 0, big.mark = ","),

    `Final employment (jobs)` =
      formatC(final * 1000, format = "f", digits = 0, big.mark = ","),

    `Revision (jobs)` =
      formatC(revision * 1000, format = "f", digits = 0, big.mark = ","),

    `Revision (%)` =
      paste0(round(pct_revision * 100, 2), "%")
  ) |>
  as.data.frame()

# HTML table
kable(
  largest_negative_table,
  caption = "Largest Negative CES Payroll Revision (Final − Original)",
  format  = "html"
)



```

The largest negative revision was in **June of 2021* at 672,000

```{r}
library(ggplot2)
library(dplyr)

p_levels <- ces_full |>
  dplyr::select(date, level) |>
  ggplot(aes(x = date, y = level)) +
  geom_line(color = "#1f78b4", linewidth = 0.8) +
  labs(
    title = "Total Nonfarm Employment (Final CES Estimates)",
    subtitle = "Seasonally Adjusted, 1979–2025",
    x = "Year",
    y = "Employment Level (Thousands)"
  ) +
  theme_minimal(base_size = 14)

p_levels


```
This plot shows the total employment level through the years. As expected, jobs numbers are increasing with a significant dip in 2020 which is also expected.
```{r}
p_revisions <- ces_full |>
  ggplot(aes(x = date, y = revision)) +
  geom_hline(yintercept = 0, color = "gray50") +
  geom_line(color = "#e31a1c", linewidth = 0.7) +
  labs(
    title = "CES Payroll Revisions Over Time",
    subtitle = "Positive = revised upward; Negative = revised downward",
    x = "Year",
    y = "Revision (Final - Original)"
  ) +
  theme_minimal(base_size = 14)

p_revisions


```

This plot shows the revisions over time with a significant spike around 2021. This can potentially be explained by the BLS "catching up" to the changes that COVID caused in 2020.

## Year with the largest jump in typical revision size (median |revision| vs previous year)
```{r}
library(dplyr)
library(knitr)

rev_change_by_year <- ces_full |> 
  group_by(year) |> 
  summarise(
    median_abs_revision = median(abs_revision, na.rm = TRUE),
    .groups = "drop"
  ) |>
  arrange(year) |>
  mutate(
    change_from_prev = median_abs_revision - lag(median_abs_revision)
  )

largest_jump <- rev_change_by_year |>
  arrange(desc(change_from_prev)) |>
  slice(1) |>
  transmute(
    Year = year,
    `Median absolute revision (jobs)` =
      formatC(median_abs_revision * 1000, format = "f", digits = 0, big.mark = ","),
    `Increase from previous year (jobs)` =
      formatC(change_from_prev * 1000, format = "f", digits = 0, big.mark = ",")
  ) |>
  as.data.frame()

kable(
  largest_jump,
  format   = "html",
  caption  = "Year with the Largest Increase in Typical CES Revision Size (Median Absolute Revision)"
)


```

2022 had the largest increase in typical revision size.

## Largest election year spike
```{r}
library(dplyr)
library(knitr)

# Define U.S. presidential election years
election_years <- c(
  1980, 1984, 1988, 1992, 1996, 2000,
  2004, 2008, 2012, 2016, 2020, 2024
)

# Mark election years in the full CES dataset
ces_full <- ces_full |>
  mutate(is_election_year = year %in% election_years)

# Compute magnitude statistics for election years only
election_magnitude_stats <- ces_full |>
  filter(is_election_year) |>        # keep election years
  group_by(year) |>
  summarise(
    mean_abs_rev   = mean(abs_revision, na.rm = TRUE),
    median_abs_rev = median(abs_revision, na.rm = TRUE),
    max_abs_rev    = max(abs_revision, na.rm = TRUE),
    .groups = "drop"
  ) |>
  arrange(desc(max_abs_rev)) |>      # sort by largest spike
  transmute(
    Year = year,
    `Mean absolute revision (jobs)` =
      formatC(mean_abs_rev * 1000, format = "f", digits = 0, big.mark = ","),
    `Median absolute revision (jobs)` =
      formatC(median_abs_rev * 1000, format = "f", digits = 0, big.mark = ","),
    `Maximum single-month revision (jobs)` =
      formatC(max_abs_rev * 1000, format = "f", digits = 0, big.mark = ",")
  ) |>
  as.data.frame()

# Render clean HTML table
kable(
  election_magnitude_stats,
  format  = "html",
  caption = "Magnitude of CES Revisions in Presidential Election Years (Sorted by Largest Monthly Spike)"
)

```



```{r}
# direction
election_direction_stats <- ces_full |>
  group_by(year) |>
  filter(is_election_year) |>
  summarize(
    mean_signed_rev   = mean(revision, na.rm = TRUE),
    median_signed_rev = median(revision, na.rm = TRUE),
    min_signed_rev    = min(revision, na.rm = TRUE),
    max_signed_rev    = max(revision, na.rm = TRUE)
  )




election_direction_table <- election_direction_stats |>
  mutate(
    Year = year,
    `Mean revision (jobs)`   = round(mean_signed_rev * 1000, 0),
    `Median revision (jobs)` = round(median_signed_rev * 1000, 0),
    `Most negative revision (jobs)` = round(min_signed_rev * 1000, 0),
    `Most positive revision (jobs)` = round(max_signed_rev * 1000, 0)
  ) |>
  select(
    Year,
    `Mean revision (jobs)`,
    `Median revision (jobs)`,
    `Most negative revision (jobs)`,
    `Most positive revision (jobs)`
  ) |>
  mutate(across(-Year, ~ formatC(.x, format = "f", digits = 0, big.mark = ","))) |>
  as.data.frame()

knitr::kable(
  election_direction_table,
  format  = "html",
  caption = "Direction of CES Payroll Revisions in Election Years"
)

```


```{r, fig.width=8, fig.height=8}
library(ggplot2)

ggplot(ces_full, aes(x = date, y = abs_revision,
                     color = is_election_year)) +
  geom_line(linewidth = 0.8) +
  scale_color_manual(values = c("FALSE" = "gray60",
                                "TRUE"  = "red")) +
  labs(
    title = "Magnitude of CES Revisions Over Time (Election Years Highlighted)",
    subtitle = "Election years in red — shows magnitude spikes",
    x = "Year",
    y = "Absolute Revision",
    color = "Election Year?"
  ) +
  theme_minimal(base_size = 14)


```

```{r}
ggplot(ces_full, aes(x = date, y = revision,
                     color = is_election_year)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_line(linewidth = 0.8) +
  scale_color_manual(values = c("FALSE" = "gray60",
                                "TRUE"  = "blue")) +
  labs(
    title = "Signed CES Revisions (Election Years Highlighted)",
    subtitle = "Shows whether revisions trended upward or downward",
    x = "Year",
    y = "Revision",
    color = "Election Year?"
  ) +
  theme_minimal(base_size = 14)


```

```{r}


library(dplyr)
library(ggplot2)
library(plotly)

##  Election years + colors 

election_years <- c(1980, 1984, 1988, 1992, 1996, 2000,
                    2004, 2008, 2012, 2016, 2020, 2024)

election_colors <- c(
  "1980" = "#D11149",
  "1984" = "#0081A7",
  "1988" = "#F17105",
  "1992" = "#9A3DFF",
  "1996" = "#2EC4B6",
  "2000" = "#FFD23F",
  "2004" = "#A0522D",
  "2008" = "#1B4965",
  "2012" = "#FF6B6B",
  "2016" = "#4CAF50",
  "2020" = "#FB8500",
  "2024" = "#8E7DBE"
)

## Make sure the helper columns exist on ces_full

ces_mag_plot <- ces_full |>
  mutate(
    abs_rev        = abs_revision,
    is_election_year = year %in% election_years,
    election_factor  = factor(year)
  )

## Build the ggplot version with Thin lines

p_mag <- ggplot() +
  # grey background: all months, very thin
  geom_line(
    data = ces_mag_plot,
    aes(x = date, y = abs_rev),
    color = "grey70",
    linewidth = 0.2,   
    alpha = 0.7
  ) +
  # election years: colored
  geom_line(
    data = ces_mag_plot |> filter(is_election_year),
    aes(x = date, y = abs_rev, color = election_factor),
    linewidth = 0.8
  ) +
  scale_color_manual(
    values = election_colors,
    name   = "Election Year"
  ) +
  labs(
    title    = "Magnitude of CES Revisions (Absolute Values)",
    subtitle = "Election years highlighted — grey background shows all months",
    x        = "Year",
    y        = "Absolute Revision"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    legend.title    = element_text(size = 12),
    legend.text     = element_text(size = 10)
  )

## Convert to interactive plotly

ggplotly(p_mag)


```







```{r, fig.width=8, fig.height=8}
library(plotly)
library(dplyr)
library(ggplot2)
library(lubridate)

# Election years and colors
election_years <- c(1980, 1984, 1988, 1992, 1996, 2000,
                    2004, 2008, 2012, 2016, 2020, 2024)

election_colors <- c(
  "1980" = "#E63946",
  "1984" = "#1D3557",
  "1988" = "#F4A261",
  "1992" = "#2A9D8F",
  "1996" = "#A8DADC",
  "2000" = "#E9C46A",
  "2004" = "#264653",
  "2008" = "#9B5DE5",
  "2012" = "#F15BB5",
  "2016" = "#00BBF9",
  "2020" = "#00F5D4",
  "2024" = "#FF8500"
)

# Prep data for direction plot
ces_dir_plot <- ces_full |>
  filter(!is.na(revision), !is.na(date)) |>
  mutate(
    is_election_year = year %in% election_years,
    election_factor  = factor(year)
  )

# Thin + distinct colors
p_dir <- ggplot() +
  # background: all months in light grey, thin
  geom_line(
    data = ces_dir_plot,
    aes(x = date, y = revision),
    color = "grey80", linewidth = 0.2, alpha = 0.7
  ) +
  # election years: colored, slightly thicker
  geom_line(
    data = ces_dir_plot |> filter(is_election_year),
    aes(x = date, y = revision, color = election_factor),
    linewidth = 0.6
  ) +
  geom_hline(yintercept = 0, linetype = "dashed", linewidth = 0.3) +
  scale_color_manual(values = election_colors, name = "Election Year") +
  labs(
    title    = "Direction of CES Revisions (Signed Values)",
    subtitle = "Election years highlighted — positive vs negative revisions",
    x = "Year",
    y = "Revision (Final - Original)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 12),
    legend.text  = element_text(size = 10)
  )

ggplotly(p_dir)

```

## Fraction of Revisions > 100k



```{r}
#Flag months with revision >100k
library(dplyr)

ces_full <- ces_full |>
  mutate(
    big_rev_100k = abs(revision) >= 100  # 100 = 100,000 jobs
  )
#Share of months with rev > 100k
big_rev_overall <- ces_full |>
  summarise(
    n_months   = n(),
    n_big_rev  = sum(big_rev_100k, na.rm = TRUE),
    frac_big   = n_big_rev / n_months
  )


big_rev_overall_table <- big_rev_overall |>
  mutate(
    `Total months` = n_months,
    `Months with |revision| ≥ 100k` = n_big_rev,
    `Share of months (%)` = round(frac_big * 100, 2)
  ) |>
  select(
    `Total months`,
    `Months with |revision| ≥ 100k`,
    `Share of months (%)`
  ) |>
  as.data.frame()

knitr::kable(
  big_rev_overall_table,
  format  = "html",
  caption = "Overall Frequency of CES Payroll Revisions ≥ 100,000 Jobs"
)




```

## How rare are > 100k revisions?




```{r}
big_rev_by_decade <- ces_full |>
  group_by(decade) |>
  summarise(
    n_months  = n(),
    n_big_rev = sum(big_rev_100k, na.rm = TRUE),
    frac_big  = n_big_rev / n_months,
    .groups = "drop"
  )


big_rev_by_decade_table <- big_rev_by_decade |>
  arrange(decade) |>
  mutate(
    `Total months` = n_months,
    `Months with |revision| ≥ 100k` = n_big_rev,
    `Share of months (%)` = round(frac_big * 100, 2)
  ) |>
  select(
    Decade = decade,
    `Total months`,
    `Months with |revision| ≥ 100k`,
    `Share of months (%)`
  ) |>
  as.data.frame()

knitr::kable(
  big_rev_by_decade_table,
  format  = "html",
  caption = "How Rare Are CES Payroll Revisions ≥ 100,000 Jobs?"
)



```

```{r}
library(ggplot2)
library(scales)

p_big_decade <- ggplot(big_rev_by_decade,
                       aes(x = factor(decade), y = frac_big)) +
  geom_col(fill = "#0081A7") +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  labs(
    title    = "How Often Do CES Revisions Exceed ±100,000 Jobs?",
    subtitle = "Share of months with |revision| ≥ 100,000 jobs by decade",
    x        = "Decade",
    y        = "Months with big revisions (%)"
  ) +
  theme_minimal(base_size = 14)

p_big_decade


```

## Fraction of “Downward” Revisions Over Time (Trend Slope)



```{r}

# Downward revisions
library(dplyr)
library(knitr)

ces_full <- ces_full |>
  mutate(
    is_down = revision < 0
  )

down_frac_decade <- ces_full |>
  group_by(decade) |>
  summarise(
    n_months  = n(),
    n_down    = sum(is_down, na.rm = TRUE),
    frac_down = n_down / n_months,
    .groups = "drop"
  )

# HTML table 
down_frac_decade |>
  mutate(
    `Share of downward revisions (%)` = round(frac_down * 100, 2)
  ) |>
  select(
    Decade = decade,
    `Total months` = n_months,
    `Months with downward revisions` = n_down,
    `Share of downward revisions (%)`
  ) |>
  as.data.frame() |>
  kable(
    format  = "html",
    caption = "Share of Months with Downward CES Payroll Revisions, by Decade"
  )



```

## Trend slope over time (logistic regression)


Pr(downward) = β0 + β1 * year




```{r}

library(broom)
library(dplyr)
library(knitr)
trend_down <- glm(
  is_down ~ year,
  data = ces_full,
  family = binomial()
)



trend_down_table <- tidy(trend_down) |>
  mutate(
    term = recode(term,
                  `(Intercept)` = "Intercept",
                  year = "Year (trend)"),
    Estimate = round(estimate, 4),
    `Std. Error` = round(std.error, 4),
    `z value` = round(statistic, 3),
    `p-value` = signif(p.value, 3)
  ) |>
  select(
    Term = term,
    Estimate,
    `Std. Error`,
    `z value`,
    `p-value`
  ) |>
  as.data.frame()

kable(
  trend_down_table,
  format  = "html",
  caption = "Logistic Regression: Trend in Probability of Downward CES Revisions"
)



```



```{r, fig.width=8, fig.height=8}
#annual averages 

down_yearly <- ces_full |>
  group_by(year) |>
  summarise(frac_down = mean(is_down, na.rm = TRUE))

#plot
library(ggplot2)
library(scales)

p_down_trend <- ggplot(down_yearly, aes(x = year, y = frac_down)) +
  geom_line(color = "#E63946", linewidth = 1.1) +
  geom_smooth(method = "lm", se = TRUE, color = "#1D3557") +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  labs(
    title = "Fraction of Downward CES Revisions Over Time",
    subtitle = "Red = actual yearly share; Blue = linear trend",
    x = "Year",
    y = "Percent of months with downward revisions"
  ) +
  theme_minimal(base_size = 14)

ggplotly(p_down_trend)


```


## Longest Run of Downward Revisions
```{r}
ces_signed <- ces_full |>
  arrange(date) |>
  mutate(down = revision < 0) |>
  filter(!is.na(down))          # remove months with missing revision

r <- rle(ces_signed$down)

down_streak_lengths <- r$lengths[r$values == TRUE]

max_down_streak <- max(down_streak_lengths)
max_down_streak

# index where each streak starts
ends   <- cumsum(r$lengths)
starts <- ends - r$lengths + 1

# keep only TRUE (down) streaks
down_starts <- starts[r$values == TRUE]
down_ends   <- ends[r$values == TRUE]

# pick the longest streak index
i <- which.max(down_streak_lengths)

longest_start_row <- down_starts[i]
longest_end_row   <- down_ends[i]

longest_down_run <- ces_signed |>
  slice(longest_start_row:longest_end_row)
cat(
  "The longest consecutive run of downward CES payroll revisions lasted",
  max_down_streak,
  "months."
)




```

## Top 5 downward runs




```{r}

# Longest runs of downward CES revisions


library(dplyr)
library(lubridate)
library(ggplot2)


# Flag months with downward revisions

ces_down <- ces_full |>
  arrange(date) |>                     # chronological order
  mutate(
    is_down = revision < 0              # TRUE if revision is negative
  )


#  Identify consecutive runs using run-length encoding
#    Each run (up or down) gets a unique run_id

run_id_vec <- with(
  rle(ces_down$is_down),
  rep(seq_along(values), lengths)
)

ces_down <- ces_down |>
  mutate(run_id = run_id_vec)


#  Summarize only the downward runs

down_runs <- ces_down |>
  filter(is_down) |>                   # keep only negative revisions
  group_by(run_id) |>
  summarise(
    start_date = min(date),
    end_date   = max(date),
    n_months   = n(),                   # length of the streak
    .groups    = "drop"
  )


# Select the top 5 longest downward streak
down_runs_top5 <- down_runs |>
  arrange(desc(n_months)) |>
  slice_head(n = 5)


# Format table 


top5_down_runs_table <- down_runs_top5 |>
  transmute(
    `Start date`        = start_date,
    `End date`          = end_date,
    `Length (months)`   = n_months
  ) |>
  as.data.frame()

knitr::kable(
  top5_down_runs_table,
  format  = "html",
  caption = "Top 5 Longest Consecutive Runs of Downward CES Payroll Revisions"
)





```

```{r, fig.width=8, fig.height=8}
ggplot(ces_full, aes(x = date, y = revision)) +
  # shaded bands for the longest downward streaks
  geom_rect(
    data = down_runs_top5,
    aes(xmin = start_date,
        xmax = end_date,
        ymin = -Inf,
        ymax = Inf,
        fill = factor(run_id)),
    inherit.aes = FALSE,
    alpha = 0.18,
    color = NA
  ) +
  # full revision time series
  geom_line(color = "grey30", linewidth = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed", linewidth = 0.3) +
  scale_fill_brewer(palette = "Set2", name = "Downward run\n(ID)") +
  labs(
    title    = "Longest Streaks of Consecutive Downward CES Revisions",
    subtitle = "Colored bands show the five longest stretches where revisions were negative every month",
    x        = "Year",
    y        = "Revision (Final – Original, thousands)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    legend.title    = element_text(size = 11),
    legend.text     = element_text(size = 9)
  )


```

## Job growth and Revision

```{r}
#payrole change
ces_gain <- ces_full |>
  arrange(date) |>
  mutate(
    payroll_change = level - lag(level)
  ) |>
  filter(!is.na(payroll_change))
#large gains
gain_threshold <- quantile(ces_gain$payroll_change, 0.9, na.rm = TRUE)
#groups
ces_gain <- ces_gain |>
  mutate(
    large_gain = payroll_change >= gain_threshold,
    abs_rev    = abs_revision
  )


```

```{r}
library(dplyr)

#  Compute month-to-month payroll change and bin into quantiles
ces_growth_bins <- ces_full |>
  arrange(date) |>
  mutate(
    payroll_change = level - dplyr::lag(level)
  ) |>
  filter(!is.na(payroll_change), !is.na(revision)) |>
  mutate(
    growth_bin = dplyr::ntile(payroll_change, 5)  # 1 = weakest, 5 = strongest growth
  )

#For each growth bin: mean signed revision and fraction downward
growth_bin_stats <- ces_growth_bins |>
  group_by(growth_bin) |>
  summarise(
    mean_revision   = mean(revision, na.rm = TRUE),
    frac_downward   = mean(revision < 0, na.rm = TRUE),
    n_months        = n(),
    .groups = "drop"
  ) |>
  mutate(
    growth_bin = factor(
      growth_bin,
      levels = 1:5,
      labels = c(
        "Q1: biggest losses",
        "Q2",
        "Q3",
        "Q4",
        "Q5: biggest gains"
      )
    ),
    frac_downward_pct = 100 * frac_downward
  )

# Format table for presentation


growth_bin_table <- growth_bin_stats |>
  transmute(
    `Growth quintile` = growth_bin,

    `Mean revision (thousands)` =
      round(mean_revision, 1),

    `Months with downward revision (%)` =
      paste0(round(frac_downward_pct, 1), "%"),

    `Number of months` = n_months
  ) |>
  as.data.frame()

knitr::kable(
  growth_bin_table,
  format  = "html",
  caption = "CES Revision Behavior by Payroll Growth Quintile"
)


```
## Plots
```{r}
library(ggplot2)
library(plotly)

p_bins <- ggplot(growth_bin_stats,
                 aes(x = growth_bin, y = mean_revision)) +
  geom_col(fill = "#1f77b4", alpha = 0.8) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Average CES Revision by Job-Growth Quintile",
    subtitle = "Quintiles based on month-to-month change in total nonfarm payrolls",
    x = "Job-growth quintile (Q1 = biggest losses, Q5 = biggest gains)",
    y = "Mean revision (final - original, thousands)"
  ) +
  theme_minimal(base_size = 14)

ggplotly(p_bins, tooltip = c("x", "y"))



``` 

```{r}

p_frac <- ggplot(growth_bin_stats,
                 aes(x = growth_bin, y = frac_downward_pct)) +
  geom_col(fill = "#ff7f0e", alpha = 0.8) +
  labs(
    title = "Share of Months with Downward Revisions by Job-Growth Quintile",
    x = "Job-growth quintile",
    y = "Downward revisions (%)"
  ) +
  theme_minimal(base_size = 14)

ggplotly(p_frac, tooltip = c("x", "y"))


```

## Revision as a % of Total Payroll Base

```{r}


pct_payroll_by_decade <- ces_full |>
  mutate(
    pct_of_payroll = abs(revision) / level
  ) |>
  group_by(decade) |>
  summarise(
    mean_pct_payroll   = mean(pct_of_payroll, na.rm = TRUE) * 100,
    median_pct_payroll = median(pct_of_payroll, na.rm = TRUE) * 100,
    max_pct_payroll    = max(pct_of_payroll, na.rm = TRUE) * 100,
    n_months           = n(),
    .groups = "drop"
  ) |>
  arrange(decade)



# Format table for presentation 

pct_payroll_table <- pct_payroll_by_decade |>
  transmute(
    `Decade` = decade,

    `Mean (% of payroll)` =
      paste0(round(mean_pct_payroll, 3), "%"),

    `Median (% of payroll)` =
      paste0(round(median_pct_payroll, 3), "%"),

    `Max (% of payroll)` =
      paste0(round(max_pct_payroll, 3), "%"),

    `Number of months` = n_months
  ) |>
  as.data.frame()

knitr::kable(
  pct_payroll_table,
  format  = "html",
  caption = "CES Revisions as a Percentage of Payroll, by Decade"
)


```









```{r}

ggplot(pct_payroll_by_decade,
       aes(x = decade, y = mean_pct_payroll)) +
  geom_line(linewidth = 1.2, color = "#1D3557") +
  geom_point(size = 3, color = "#E63946") +
  labs(
    title = "CES Revisions as Percent of Payroll Over Time",
    x = "Decade",
    y = "Mean Absolute Revision (% of Payroll)"
  ) +
  theme_minimal(base_size = 14)



```

# Statistical Analysis

## T-test: Are revisions larger after big payroll gains?

```{r}
library(infer)
library(dplyr)


# Compare revision size after large vs normal payroll gains


#  Compute month-to-month payroll change and absolute revision size
ces_gain <- ces_full |>
  arrange(date) |>
  mutate(
    payroll_change = level - lag(level),   # monthly payroll change
    abs_rev        = abs(revision)          # absolute revision size
  ) |>
  filter(!is.na(payroll_change), !is.na(abs_rev))

#  Define "large payroll gain" as the top 10% of monthly changes
gain_threshold <- quantile(
  ces_gain$payroll_change,
  0.9,
  na.rm = TRUE
)

#  Classify months
ces_gain <- ces_gain |>
  mutate(
    large_gain = if_else(
      payroll_change >= gain_threshold,
      "Large gain",
      "Normal / low"
    )
  )

# Two-sample t-test
# H0: Mean absolute revision is the same for both groups
# HA: Mean absolute revision differs
ttest_large_gain <- ces_gain |>
  t_test(
    abs_rev ~ large_gain,
    order = c("Normal / low", "Large gain")
  )




# Summary table for presentation


ttest_large_gain_table <- ttest_large_gain |>
  transmute(
    `t statistic`        = round(statistic, 3),
    `Degrees of freedom` = round(t_df, 2),
    `p-value`            = round(p_value, 3),
    `Alternative`        = alternative,
    `Estimated difference (Large − Normal)` = round(estimate, 3),
    `95% CI lower`       = round(lower_ci, 3),
    `95% CI upper`       = round(upper_ci, 3)
  ) |>
  as.data.frame()

kable(
  ttest_large_gain_table,
  format  = "html",
  caption = "Two-sample t-test: Are absolute CES revisions larger after big payroll gains?"
)

```


## Bootstrap Analysis

0.95 CL

```{r}
library(infer)
library(dplyr)
library(knitr)


# PERMUTATION TEST
# H0: Absolute revisions are independent of large payroll gains


set.seed(123)

perm_large_gain <- ces_gain |>
  specify(abs_rev ~ large_gain) |>
  hypothesize(null = "independence") |>
  generate(reps = 2000, type = "permute") |>
  calculate(
    stat  = "diff in means",
    order = c("Large gain", "Normal / low")
  )

# observed statistic (same scale as permutation)
obs_diff <- ces_gain |>
  specify(abs_rev ~ large_gain) |>
  calculate(
    stat  = "diff in means",
    order = c("Large gain", "Normal / low")
  )

# permutation p-value (two-sided)
perm_pval <- get_p_value(
  perm_large_gain,
  obs_stat = obs_diff$stat,
  direction = "two-sided"
)


# BOOTSTRAP CONFIDENCE INTERVAL
# Estimates uncertainty around the same statistic


boot_large_gain <- ces_gain |>
  specify(abs_rev ~ large_gain) |>
  generate(reps = 2000, type = "bootstrap") |>
  calculate(
    stat  = "diff in means",
    order = c("Large gain", "Normal / low")
  )

boot_large_gain_ci <- boot_large_gain |>
  get_confidence_interval(type = "percentile")


# table


boot_large_gain_ci_table <- boot_large_gain_ci |>
  transmute(
    `95% CI lower` = round(lower_ci, 3),
    `95% CI upper` = round(upper_ci, 3)
  ) |>
  as.data.frame()

knitr::kable(
  boot_large_gain_ci_table,
  format  = "html",
  caption = "Bootstrap 95% CI for Difference in Mean Absolute Revisions  
             (Large Gain − Normal/Low)"
)


```





```{r}
library(infer)
library(dplyr)
library(knitr)


# PURPOSE:
# Use a bootstrap (computational inference) to estimate
# the sampling distribution of the MEDIAN CES revision.
# This avoids normality assumptions and targets the median,
# not the mean.


# Keep only months with observed revisions
ces_rev_ok <- ces_full |>
  filter(!is.na(revision))


# BOOTSTRAP:
# Repeatedly resample months and replacement and
# compute the median revision each time.
# This approximates the sampling distribution of the median.

set.seed(123)

boot_median_rev <- ces_rev_ok |>
  specify(response = revision) |>
  generate(reps = 2000, type = "bootstrap") |>
  calculate(stat = "median")


# CONFIDENCE INTERVAL:
# Percentile-based 95% bootstrap confidence interval
# for the population median revision.

boot_median_ci <- boot_median_rev |>
  get_confidence_interval(
    level = 0.95,
    type  = "percentile"
  )


# table
boot_median_ci_table <- boot_median_ci |>
  transmute(
    `95% CI lower (thousands of jobs)` = round(lower_ci, 2),
    `95% CI upper (thousands of jobs)` = round(upper_ci, 2)
  ) |>
  as.data.frame()

knitr::kable(
  boot_median_ci_table,
  format  = "html",
  caption = "Bootstrap 95% Confidence Interval for the Median CES Revision"
)



```

```{r}
# Observed (sample) median CES revision
# This is the actual median revision in the data (in thousands of jobs),
# NOT a model-based or resampled estimate
obs_median_rev <- ces_rev_ok |>
  summarise(
    median_revision = median(revision, na.rm = TRUE)
  )

# Format the result for presentation

obs_median_rev_table <- obs_median_rev |>
  transmute(
    `Median CES revision (thousands of jobs)` = median_revision
  ) |>
  as.data.frame()

# Display as HTML table
knitr::kable(
  obs_median_rev_table,
  format  = "html",
  caption = "Observed Median CES Payroll Revision"
)



```

## Are Downward revisions more common in Democratic or Republican Precidencies?

```{r}
library(dplyr)
library(lubridate)
library(infer)
library(knitr)

## 1. Build president/party lookup 
presidents_party <- tidyr::expand_grid(
  year      = 1979:2025,
  month     = month.name,
  president = NA_character_,
  party     = NA_character_
) |>
  mutate(
    # Hard–code which president takes office in which month/year
    president = case_when(
      month == "January"  & year == 1979 ~ "Carter",
      month == "February" & year == 1981 ~ "Reagan",
      month == "February" & year == 1989 ~ "Bush 41",
      month == "February" & year == 1993 ~ "Clinton",
      month == "February" & year == 2001 ~ "Bush 43",
      month == "February" & year == 2009 ~ "Obama",
      month == "February" & year == 2017 ~ "Trump I",
      month == "February" & year == 2021 ~ "Biden",
      month == "February" & year == 2025 ~ "Trump II",
      .default = NA_character_
    )
  ) |>
  tidyr::fill(president) |>
  mutate(
    # Map presidents to party label: D = Democrat, R = Republican
    party = if_else(
      president %in% c("Carter", "Clinton", "Obama", "Biden"),
      "D", "R"
    )
  )

## Join to CES and create downward indicator 
ces_party <- ces_full |>
  mutate(
    year  = year(date),
    month = month(date, label = TRUE, abbr = FALSE) |> as.character()
  ) |>
  left_join(presidents_party, by = c("year", "month")) |>
  filter(!is.na(party), !is.na(revision)) |>
  mutate(
    downward      = revision < 0,                       # TRUE if revision is negative
    downward_chr  = if_else(downward, "down", "up"),    # character version for infer()
    party         = factor(party, levels = c("R", "D")) # order: Republicans, then Democrats
  )

##  fraction of downward revisions by party
# Here we just describe how often revisions are negative under each party
party_downward_summary <- ces_party |>
  group_by(party) |>
  summarise(
    n_months  = n(),                          # total months for that party
    n_down    = sum(downward),                # number of months with downward revision
    frac_down = n_down / n_months,            # share of months with downward revision
    .groups   = "drop"
  )

# Format descriptive results as a clean HTML table
party_downward_table <- party_downward_summary |>
  mutate(
    `Share downward (%)` = round(100 * frac_down, 1)
  ) |>
  transmute(
    Party                           = as.character(party),
    `Total months`                  = n_months,
    `Months with downward revision` = n_down,
    `Share downward (%)`
  ) |>
  as.data.frame()

kable(
  party_downward_table,
  format  = "html",
  caption = "Share of Months with Downward CES Revisions, by President’s Party"
)

## 4. Classical prop_test (theory-based χ² test) 
# Formal test of H0: probability of a downward revision is the same under R and D
# prop_test() does a 2×2 chi-square test on downward (yes/no) by party (R/D)
prop_party <- ces_party |>
  prop_test(downward ~ party,
            order = c("R", "D"))   # CI is for p(D) − p(R)

# Format prop_test output as a small inferential summary table


```

```{r}

prop_party_table <- prop_party |>
  transmute(
    `Chi-square statistic`          = round(statistic, 3),
    `Degrees of freedom`           = chisq_df,
    `p-value`                      = round(p_value, 3),
    `Alternative hypothesis`       = alternative,
    `95% CI lower (p[D] − p[R])`   = round(lower_ci, 3),
    `95% CI upper (p[D] − p[R])`   = round(upper_ci, 3)
  ) |>
  as.data.frame()

kable(
  prop_party_table,
  format  = "html",
  caption = "Theory-based Test: Difference in Probability of Downward Revisions (Democrats − Republicans)"
)
```

```{r}
##  EXTRA CREDIT: permutation + bootstrap with infer 
# Observed difference in proportions: p_D - p_R
obs_party_diff <- ces_party |>
  specify(response = downward_chr,
          explanatory = party,
          success = "down") |>           # "success" level is the string "down"
  calculate(stat = "diff in props",
            order = c("D", "R"))         # p_D - p_R



#  Permutation test under H0: no party effect on downward probability
set.seed(123)

perm_party <- ces_party |>
  specify(downward_chr ~ party, success = "down") |>
  hypothesize(null = "independence") |>
  generate(reps = 2000, type = "permute") |>
  calculate(stat = "diff in props",
            order = c("D", "R"))

# two-sided p-value from permutation distribution
perm_pval <- get_p_value(
  perm_party,
  obs_stat   = obs_party_diff$stat,
  direction  = "two-sided"
)



#  Bootstrap CI for p_D - p_R (computational CI)
set.seed(123)

boot_party <- ces_party |>
  specify(downward_chr ~ party, success = "down") |>
  generate(reps = 2000, type = "bootstrap") |>
  calculate(stat = "diff in props",
            order = c("D", "R"))

boot_ci <- boot_party |>
  get_confidence_interval(level = 0.95, type = "percentile")



#Summarise permutation + bootstrap results in one table 



party_comp_summary <- tibble::tibble(
  `Estimate p(D) − p(R)`          = round(obs_party_diff$stat, 3),
  `Permutation p-value`           = round(perm_pval$p_value, 3),
  `Bootstrap 95% CI lower`        = round(boot_ci$lower_ci, 3),
  `Bootstrap 95% CI upper`        = round(boot_ci$upper_ci, 3)
) |>
  as.data.frame()

knitr::kable(
  party_comp_summary,
  format  = "html",
  caption = "Computational Inference for Difference in Downward-Revision Probabilities (Democrats − Republicans)"
)




```


# Claim 1: "Bureau of Labor Statistics employment numbers “were rigged” when the agency revised them “down by almost 900,000 jobs” after the 2024 election." -Donald Trump(2025)
```{r}
library(dplyr)
library(knitr)

# Largest NEGATIVE revision (most negative Final - Original)
largest_negative <- ces_full |>
  filter(!is.na(revision)) |>
  arrange(revision) |>        # most negative first
  slice(1)

# Format for HTML table
largest_negative_table <- largest_negative |>
  transmute(
    Date = date,

    `Payroll level (jobs)` =
      formatC(level * 1000, format = "f", digits = 0, big.mark = ","),

    `Original employment (jobs)` =
      formatC(original * 1000, format = "f", digits = 0, big.mark = ","),

    `Final employment (jobs)` =
      formatC(final * 1000, format = "f", digits = 0, big.mark = ","),

    `Revision (jobs)` =
      formatC(revision * 1000, format = "f", digits = 0, big.mark = ","),

    `Revision (%)` =
      paste0(round(pct_revision * 100, 2), "%")
  ) |>
  as.data.frame()

# HTML table
kable(
  largest_negative_table,
  caption = "Largest Negative CES Payroll Revision (Final − Original)",
  format  = "html"
)



```



Using the data from Task 3, we see that the largest **downward** revision was in June of 2021 at 672,000 jobs which 1st of all was **not** in 2024 and was nowhere near a loss of 900,000 jobs. In the following visualization, notice the "spike" downward around the year 2021.
Covid was likely the driver of the huge negative revision in 2021.
```{r}
p_revisions <- ces_full |>
  ggplot(aes(x = date, y = revision)) +
  geom_hline(yintercept = 0, color = "gray50") +
  geom_line(color = "#e31a1c", linewidth = 0.7) +
  labs(
    title = "CES Payroll Revisions Over Time",
    subtitle = "Positive = revised upward; Negative = revised downward",
    x = "Year",
    y = "Revision (Final - Original)"
  ) +
  theme_minimal(base_size = 14)

p_revisions


```

From Task 3 we determined how rare are huge revisions so revisions > 100k. 
```{r}
big_rev_by_decade <- ces_full |>
  group_by(decade) |>
  summarise(
    n_months  = n(),
    n_big_rev = sum(big_rev_100k, na.rm = TRUE),
    frac_big  = n_big_rev / n_months,
    .groups = "drop"
  )


big_rev_by_decade_table <- big_rev_by_decade |>
  arrange(decade) |>
  mutate(
    `Total months` = n_months,
    `Months with |revision| ≥ 100k` = n_big_rev,
    `Share of months (%)` = round(frac_big * 100, 2)
  ) |>
  select(
    Decade = decade,
    `Total months`,
    `Months with |revision| ≥ 100k`,
    `Share of months (%)`
  ) |>
  as.data.frame()

knitr::kable(
  big_rev_by_decade_table,
  format  = "html",
  caption = "How Rare Are CES Payroll Revisions ≥ 100,000 Jobs?"
)



```


Compared to previous decades two decades, the 2020's do seem to have an unusually high frequency of monthly revisions at **18.18%** but do not have the highest frequency of monthly revisions. However, this discrepancy can probably mostly be accounted for by the huge spike in 2021. 
```{r}
library(ggplot2)
library(scales)

p_big_decade <- ggplot(big_rev_by_decade,
                       aes(x = factor(decade), y = frac_big)) +
  geom_col(fill = "#0081A7") +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  labs(
    title    = "How Often Do CES Revisions Exceed ±100,000 Jobs?",
    subtitle = "Share of months with |revision| ≥ 100,000 jobs by decade",
    x        = "Decade",
    y        = "Months with big revisions (%)"
  ) +
  theme_minimal(base_size = 14)

p_big_decade
```



Finally, we computed in Task 3, the most negative monthly revision in an election year.

```{r}
# direction
election_direction_stats <- ces_full |>
  group_by(year) |>
  filter(is_election_year) |>
  summarize(
    mean_signed_rev   = mean(revision, na.rm = TRUE),
    median_signed_rev = median(revision, na.rm = TRUE),
    min_signed_rev    = min(revision, na.rm = TRUE),
    max_signed_rev    = max(revision, na.rm = TRUE)
  )




election_direction_table <- election_direction_stats |>
  mutate(
    Year = year,
    `Mean revision (jobs)`   = round(mean_signed_rev * 1000, 0),
    `Median revision (jobs)` = round(median_signed_rev * 1000, 0),
    `Most negative revision (jobs)` = round(min_signed_rev * 1000, 0),
    `Most positive revision (jobs)` = round(max_signed_rev * 1000, 0)
  ) |>
  select(
    Year,
    `Mean revision (jobs)`,
    `Median revision (jobs)`,
    `Most negative revision (jobs)`,
    `Most positive revision (jobs)`
  ) |>
  mutate(across(-Year, ~ formatC(.x, format = "f", digits = 0, big.mark = ","))) |>
  as.data.frame()

knitr::kable(
  election_direction_table,
  format  = "html",
  caption = "Direction of CES Payroll Revisions in Election Years"
)

```
We can see that in 2024, the most negative revision was *104,000* comparable to previous election years. 

```{r}
library(plotly)
library(dplyr)
library(ggplot2)
library(lubridate)

# Election years and colors
election_years <- c(1980, 1984, 1988, 1992, 1996, 2000,
                    2004, 2008, 2012, 2016, 2020, 2024)

election_colors <- c(
  "1980" = "#E63946",
  "1984" = "#1D3557",
  "1988" = "#F4A261",
  "1992" = "#2A9D8F",
  "1996" = "#A8DADC",
  "2000" = "#E9C46A",
  "2004" = "#264653",
  "2008" = "#9B5DE5",
  "2012" = "#F15BB5",
  "2016" = "#00BBF9",
  "2020" = "#00F5D4",
  "2024" = "#FF8500"
)

# Prep data for direction plot
ces_dir_plot <- ces_full |>
  filter(!is.na(revision), !is.na(date)) |>
  mutate(
    is_election_year = year %in% election_years,
    election_factor  = factor(year)
  )

# Thin + distinct colors
p_dir <- ggplot() +
  # background: all months in light grey, thin
  geom_line(
    data = ces_dir_plot,
    aes(x = date, y = revision),
    color = "grey80", linewidth = 0.2, alpha = 0.7
  ) +
  # election years: colored, slightly thicker
  geom_line(
    data = ces_dir_plot |> filter(is_election_year),
    aes(x = date, y = revision, color = election_factor),
    linewidth = 0.6
  ) +
  geom_hline(yintercept = 0, linetype = "dashed", linewidth = 0.3) +
  scale_color_manual(values = election_colors, name = "Election Year") +
  labs(
    title    = "Direction of CES Revisions (Signed Values)",
    subtitle = "Election years highlighted — positive vs negative revisions",
    x = "Year",
    y = "Revision (Final - Original)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 12),
    legend.text  = element_text(size = 10)
  )

ggplotly(p_dir)
```

In our plot from Task 3, 2024 doesn't really seem to stand out much from previous election years.

```{r}
ces_period <- ces_full |>
  mutate(
    period = case_when(
      date >= as.Date("2024-01-01") &
      date <= as.Date("2025-06-01") ~ "Post-2024 election",
      TRUE ~ "Historical baseline"
    )
  )

claim1_period_summary <- ces_period |>
  group_by(period) |>
  summarise(
    `Total revision (thousands)` = sum(revision, na.rm = TRUE),
    `Mean monthly revision (thousands)` = mean(revision, na.rm = TRUE),
    `Median monthly revision (thousands)` = median(revision, na.rm = TRUE),
    `Fraction of downward revisions` = mean(revision < 0, na.rm = TRUE),
    `Number of months` = n(),
    .groups = "drop"
  ) |>
  mutate(
    `Total revision (thousands)` =
      round(`Total revision (thousands)`, 1),
    `Mean monthly revision (thousands)` =
      round(`Mean monthly revision (thousands)`, 1),
    `Median monthly revision (thousands)` =
      round(`Median monthly revision (thousands)`, 1),
    `Fraction of downward revisions` =
      paste0(round(`Fraction of downward revisions` * 100, 1), "%")
  ) |>
  as.data.frame()

knitr::kable(
  claim1_period_summary,
  format  = "html",
  caption = "Claim 1: Mean, Median, and Cumulative CES Revisions Post-Election vs Historical Baseline"
)



```

We also computed revisions as a percent of the payroll, aka total jobs, in task 3. Using the levels, here we can see how tiny the revisions are compared to the total number of jobs. The yearly revisions are a very small fraction of total employment. So, there doesn't seem to be any evidence of significant "rigging" here.

##Tests
First we define post-election period
```{r}
# Define post-election period: Jan 2024 – Jun 2025
ces_claim1 <- ces_full |>
  filter(!is.na(revision)) |>
  mutate(
    period = if_else(
      date >= as.Date("2024-1-01") & date <= as.Date("2025-06-01"),
      "Post-2024 election",
      "Historical baseline"
    ),
    is_post = period == "Post-2024 election",
    is_down = revision < 0
  )




```

### Descriptive table
```{r}
period_summary <- ces_claim1 |>
  group_by(period) |>
  summarise(
    total_revision  = sum(revision, na.rm = TRUE),           # thousands of jobs
    mean_revision   = mean(revision, na.rm = TRUE),
    median_revision = median(revision, na.rm = TRUE),
    frac_down       = mean(is_down, na.rm = TRUE),
    n_months        = n(),
    .groups = "drop"
  ) |>
  mutate(
    `Total revision (thousands)`       = total_revision,
    `Mean monthly revision (thousands)`   = round(mean_revision, 1),
    `Median monthly revision (thousands)` = round(median_revision, 1),
    `Fraction of downward revisions`      = paste0(round(frac_down * 100, 1), "%"),
    `Number of months`                    = n_months
  ) |>
  select(
    period,
    `Total revision (thousands)`,
    `Mean monthly revision (thousands)`,
    `Median monthly revision (thousands)`,
    `Fraction of downward revisions`,
    `Number of months`
  )
kable(
  period_summary,
  format  = "html",
  caption = "Claim 1: Mean, Median, and Cumulative CES Revisions Post-Election vs Historical Baseline"
)

```

### Test 1: T-test for the mean
**Is the average monthly revision after the 2024 election unusually negative?** We will use a two sample t test using 'H0: mean revison of post-election period = mean of pre election period.
HA: mean of post election period does not = mean of pre election period.

```{r}
library(infer)
ttest_mean <- ces_claim1 |>
  t_test(
    revision ~ is_post,
    order = c(FALSE, TRUE)   # post − historical
  )

ttest_mean_table <- ttest_mean |>
  transmute(
    `t statistic` = round(statistic, 3),
    `df`          = round(t_df, 1),
    `p-value`     = round(p_value, 3),
    `Estimate (post − hist, thousands)` = round(estimate, 1),
    `95% CI lower` = round(lower_ci, 1),
    `95% CI upper` = round(upper_ci, 1)
  ) |>
  as.data.frame()

kable(
  ttest_mean_table,
  format  = "html",
  caption = "Claim 1 – Test 1: Difference in Mean CES Revision (Post-Election − Historical)"
)

```
Here we see a very small p-value suggesting that we reject our null hypothesis and conclude that the mean of revisions during the post election period do not equal the mean revision of historical data.

### Permutation test for the mean

```{r}
set.seed(123)
perm_mean <- ces_claim1 |>
  specify(revision ~ is_post) |>
  hypothesize(null = "independence") |>
  generate(reps = 2000, type = "permute") |>
  calculate(stat = "diff in means", order = c(TRUE, FALSE))

perm_mean_pval <- get_p_value(
  perm_mean,
  obs_stat  = ttest_mean$estimate,
  direction = "two-sided"
)

perm_mean_pval_table <- perm_mean_pval |>
  transmute(`Permutation p-value (mean diff)` = round(p_value, 3)) |>
  as.data.frame()

kable(
  perm_mean_pval_table,
  format  = "html",
  caption = "Claim 1 – Test 1 (Computational): Permutation p-value for Difference in Mean Revision"
)

```
Again we see a p-value less than .05 suggesting that there is difference in the post election mean differs from the mean of historical data under normality assumptions


### Test 2: Testing the median with bootstrap 

```{r}
set.seed(123)
boot_median_diff <- ces_claim1 |>
  specify(revision ~ is_post) |>
  generate(reps = 2000, type = "bootstrap") |>
  calculate(stat = "diff in medians", order = c(TRUE, FALSE))  # post − hist

boot_median_ci <- boot_median_diff |>
  get_confidence_interval(type = "percentile")

boot_median_ci_table <- boot_median_ci |>
  transmute(
    `95% CI lower (thousands)` = round(lower_ci, 1),
    `95% CI upper (thousands)` = round(upper_ci, 1)
  ) |>
  as.data.frame()

kable(
  boot_median_ci_table,
  format  = "html",
  caption = "Claim 1 – Test 2: Bootstrap 95% CI for Difference in Median CES Revision (Post − Historical)"
)

```

Bootstrapping repeatedly resamples the observed post-election months to estimate the uncertainty around the median revision without parametric assumptions. Given that the confidence interval does not contain 0 we cannot reject the null hypothesis suggesting that the data in the post election period is different from historical data.

### Test 3: binomial prop test
```{r}
library(infer)
library(dplyr)


ces_claim1_clean <- ces_claim1 |>
  mutate(
    # Convert the logical 'is_down' to a factor, where TRUE is the 'success' level
    is_down_factor = factor(is_down, levels = c(FALSE, TRUE), labels = c("No Down Rev", "Down Rev")),
    # Convert the logical 'is_post' (grouping variable) to a factor
    is_post_factor = factor(is_post, levels = c(FALSE, TRUE), labels = c("Historical", "Post-2015"))
  )


prop_test_result <- ces_claim1_clean |>
  # Test the proportion of 'is_down_factor' (success = 'Down Rev') 
  # across the groups defined by 'is_post_factor'
  prop_test(
    is_down_factor ~ is_post_factor,
    order = c("Historical", "Post-2015") # This sets the difference as: Post-2015 - Historical
  )

# 3. View the result
prop_test_result

```
The p-value of the prop test is still less than .05 indicating that there is statistically significant difference in the probability of getting a downward revision in the post election period vs historical data.


## Conclusions
We are not able to reject the null hypothesis that downward revisions have increased in the post-election period. While correlation does not equal causation, the results of our 3 tests indicate that there is an increased probability of getting a downward revision in the post-election period. While there is no way to tell if this was because of political bias or outright manipulation by the BLS, there is a difference in historical downward revisions and post-election period downward revisions.







# Claim 2: Stefanik (2024): “The Biden administration has been cooking the books — the jobs numbers keep getting revised down.” 

## Statistics

In task 3, we computed the top 5 longest runs of downward revisions. 

```{r}
# Longest runs of downward CES revisions


library(dplyr)
library(lubridate)
library(ggplot2)


# Flag months with downward revisions

ces_down <- ces_full |>
  arrange(date) |>                     # chronological order
  mutate(
    is_down = revision < 0              # TRUE if revision is negative
  )


#  Identify consecutive runs using run-length encoding
#    Each run (up or down) gets a unique run_id

run_id_vec <- with(
  rle(ces_down$is_down),
  rep(seq_along(values), lengths)
)

ces_down <- ces_down |>
  mutate(run_id = run_id_vec)


#  Summarize only the downward runs

down_runs <- ces_down |>
  filter(is_down) |>                   # keep only negative revisions
  group_by(run_id) |>
  summarise(
    start_date = min(date),
    end_date   = max(date),
    n_months   = n(),                   # length of the streak
    .groups    = "drop"
  )


# Select the top 5 longest downward streak
down_runs_top5 <- down_runs |>
  arrange(desc(n_months)) |>
  slice_head(n = 5)


# Format table 


top5_down_runs_table <- down_runs_top5 |>
  transmute(
    `Start date`        = start_date,
    `End date`          = end_date,
    `Length (months)`   = n_months
  ) |>
  as.data.frame()

knitr::kable(
  top5_down_runs_table,
  format  = "html",
  caption = "Top 5 Longest Consecutive Runs of Downward CES Payroll Revisions"
)
```

The claim states that the BLS had been revising numbers down consistently under Biden-nominated BLS Commisioner McEntarfer, which would imply a long run of downward revisions. While we do see a run of 6 months in 2024, it doesn't stand out. There are historical patterns of long runs, some of more than 6 months so nothing seems particularly out of the ordinary for 2024.

```{r}
ggplot(ces_full, aes(x = date, y = revision)) +
  # shaded bands for the longest downward streaks
  geom_rect(
    data = down_runs_top5,
    aes(xmin = start_date,
        xmax = end_date,
        ymin = -Inf,
        ymax = Inf,
        fill = factor(run_id)),
    inherit.aes = FALSE,
    alpha = 0.18,
    color = NA
  ) +
  # full revision time series
  geom_line(color = "grey30", linewidth = 0.35) +
  geom_hline(yintercept = 0, linetype = "dashed", linewidth = 0.3) +
  scale_fill_brewer(palette = "Set2", name = "Downward run\n(ID)") +
  labs(
    title    = "Longest Streaks of Consecutive Downward CES Revisions",
    subtitle = "Colored bands show the five longest stretches where revisions were negative every month",
    x        = "Year",
    y        = "Revision (Final – Original, thousands)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "bottom",
    legend.title    = element_text(size = 11),
    legend.text     = element_text(size = 9)
  )

```

Also in Task 3, we found fraction of revisions over time shown in the table below.
```{r}
# Downward revisions
library(dplyr)
library(knitr)

ces_full <- ces_full |>
  mutate(
    is_down = revision < 0
  )

down_frac_decade <- ces_full |>
  group_by(decade) |>
  summarise(
    n_months  = n(),
    n_down    = sum(is_down, na.rm = TRUE),
    frac_down = n_down / n_months,
    .groups = "drop"
  )

# HTML table 
down_frac_decade |>
  mutate(
    `Share of downward revisions (%)` = round(frac_down * 100, 2)
  ) |>
  select(
    Decade = decade,
    `Total months` = n_months,
    `Months with downward revisions` = n_down,
    `Share of downward revisions (%)`
  ) |>
  as.data.frame() |>
  kable(
    format  = "html",
    caption = "Share of Months with Downward CES Payroll Revisions, by Decade"
  )
```

Let's modify this table to show the revisions from 2020 to 2025

```{r}
# Downward revisions (2020–2025)
library(dplyr)
library(knitr)

ces_full_2020 <- ces_full |>
  mutate(is_down = revision < 0) |>
  filter(year >= 2020, year <= 2025)

down_frac_2020 <- ces_full_2020 |>
  group_by(year) |>
  summarise(
    n_months  = n(),
    n_down    = sum(is_down, na.rm = TRUE),
    frac_down = n_down / n_months,
    .groups = "drop"
  )

# HTML table
down_frac_2020 |>
  mutate(
    `Share of downward revisions (%)` = round(frac_down * 100, 2)
  ) |>
  select(
    Year = year,
    `Total months` = n_months,
    `Months with downward revisions` = n_down,
    `Share of downward revisions (%)`
  ) |>
  as.data.frame() |>
  kable(
    format  = "html",
    caption = "Share of Months with Downward CES Payroll Revisions (2020–2025)"
  )


```

2024 does appear to have a higher than normal share of negative revisions so there is some evidence that appears to support something going on in 2024.

```{r}
#annual averages 

down_yearly <- ces_full |>
  group_by(year) |>
  summarise(frac_down = mean(is_down, na.rm = TRUE))

#plot
library(ggplot2)
library(scales)

p_down_trend <- ggplot(down_yearly, aes(x = year, y = frac_down)) +
  geom_line(color = "#E63946", linewidth = 1.1) +
  geom_smooth(method = "lm", se = TRUE, color = "#1D3557") +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  labs(
    title = "Fraction of Downward CES Revisions Over Time",
    subtitle = "Red = actual yearly share; Blue = linear trend",
    x = "Year",
    y = "Percent of months with downward revisions"
  ) +
  theme_minimal(base_size = 14)

ggplotly(p_down_trend)
```

However when we look at the time plot of negative revisions, it fluctuates around 0% pretty consistently. There is a spike in 2024, but it looks relatively consistent with normal variation.

Also if we factor in how often are revisions > 100k during the years 2020 - 2025 we can try to see whats going on in 2024

```{r}

# Restrict to 2020–2025
big_rev_2020_2025 <- ces_full |>
  filter(year >= 2020, year <= 2025) |>
  group_by(year) |>
  summarise(
    n_months  = n(),
    n_big_rev = sum(big_rev_100k, na.rm = TRUE),
    frac_big  = n_big_rev / n_months,
    .groups   = "drop"
  )

# Format as HTML table
big_rev_2020_2025_table <- big_rev_2020_2025 |>
  arrange(year) |>
  mutate(
    `Total months` = n_months,
    `Months with |revision| ≥ 100k` = n_big_rev,
    `Share of months (%)` = round(frac_big * 100, 2)
  ) |>
  select(
    Year = year,
    `Total months`,
    `Months with |revision| ≥ 100k`,
    `Share of months (%)`
  ) |>
  as.data.frame()

knitr::kable(
  big_rev_2020_2025_table,
  format  = "html",
  caption = "Frequency of Large CES Payroll Revisions (≥100,000 Jobs), 2020–2025"
)



```

2024 only has one revision greater than 100k, so likely the revisions can just be attributed to normal data collection error and adjustment.

## Tests

In our earlier statistical analysis we tested whether or not large downward revision. The following table shows that there are more downward revisions during trumps presidency.


```{r}
library(dplyr)
library(lubridate)
library(knitr)

ces_era <- ces_full |>
  mutate(
    era = case_when(
      date >= as.Date("2020-01-01") & date <= as.Date("2023-12-01") ~ "Biden era",
      date >= as.Date("2024-01-01") & date <= as.Date("2025-06-01") ~ "Trump era",
      TRUE ~ NA_character_
    )
  ) |>
  filter(!is.na(era))
era_summary_table <- ces_era |>
  summarise(
    mean_rev_biden   = mean(revision[era == "Biden era"], na.rm = TRUE),
    mean_rev_trump   = mean(revision[era == "Trump era"], na.rm = TRUE),
    median_rev_biden = median(revision[era == "Biden era"], na.rm = TRUE),
    median_rev_trump = median(revision[era == "Trump era"], na.rm = TRUE),
    frac_down_biden  = mean(revision[era == "Biden era"] < 0, na.rm = TRUE),
    frac_down_trump  = mean(revision[era == "Trump era"] < 0, na.rm = TRUE),
    n_biden          = sum(era == "Biden era"),
    n_trump          = sum(era == "Trump era")
  ) |>
  mutate(
    `Mean revision (Biden, k)`   = round(mean_rev_biden, 1),
    `Mean revision (Trump, k)`   = round(mean_rev_trump, 1),
    `Median revision (Biden, k)` = round(median_rev_biden, 1),
    `Median revision (Trump, k)` = round(median_rev_trump, 1),
    `Downward share (Biden %)`   = round(frac_down_biden * 100, 1),
    `Downward share (Trump %)`   = round(frac_down_trump * 100, 1)
  ) |>
  select(
    `Mean revision (Biden, k)`,
    `Mean revision (Trump, k)`,
    `Median revision (Biden, k)`,
    `Median revision (Trump, k)`,
    `Downward share (Biden %)`,
    `Downward share (Trump %)`,
    `Biden months` = n_biden,
    `Trump months` = n_trump
  ) |>
  as.data.frame()

kable(
  era_summary_table,
  format  = "html",
  caption = "CES Revision Statistics: Biden Era vs Trump Era"
)


```
However, given the following p-value, there is not significant evidence that revisions under the Biden administration were larger or more negative than the Trump administration.

```{r}
t_test_era <- t.test(
  revision ~ era,
  data = ces_era,
  alternative = "two.sided"
)

t_test_era_table <- data.frame(
  `t statistic` = round(t_test_era$statistic, 3),
  `Degrees of freedom` = round(t_test_era$parameter, 1),
  `p-value` = round(t_test_era$p.value, 4),
  `Mean difference (Trump − Biden)` =
    round(diff(t_test_era$estimate), 2)
)

kable(
  t_test_era_table,
  format  = "html",
  caption = "Two-Sample t-Test: Mean CES Revisions (Trump Era − Biden Era)"
)


```


# Conclusions:
There is no direct evidence that the Biden administration ever manipulated or falsified jobs reports. While yes there was an increase in revision during the post election period of **January 2024 to June of 2025, there is no evidence that the Biden administration purposefully altered jobs reports. 



